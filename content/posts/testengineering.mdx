---
blog-title: jaffamonkey
title: test engineering
---

import { CodeWave } from "gatsby-theme-waves"

---

Test automation is only part of the path that leads to better quality with `CI` and `CD`.

When building and maintaining a test framework it should always be optimal.

### This means no clunk, clutter or useless tests.

<CodeWave>

```bash
$ curl -s -v -o /dev/null -I -w "%{http_code}" http://jaffamonkey.com
*   Trying 35.169.225.248...
* TCP_NODELAY set
* Expire in 149999 ms for 3 (transfer 0x55a114e985c0)
* Expire in 200 ms for 4 (transfer 0x55a114e985c0)
* Connected to jaffamonkey.com (35.169.225.248) port 80 (#0)
> HEAD / HTTP/1.1
> Host: jaffamonkey.com
> User-Agent: curl/7.64.0
> Accept: */*
> 
< HTTP/1.1 301 Moved Permanently
< Date: Fri, 26 Jul 2019 11:49:40 GMT
< Connection:Keep-Alive
< Content-Length: 0
< Cache-Control: private, no-cache, no-store, max-age=0
< Expires: Mon, 01 Jan 1990 0:00:00 GMT
< Location: https://jaffamonkey.netlify.com
< 
* Connection #0 to host jaffamonkey.com left intact
```
It's all about what's appropriate, to both development and business sides to a project.

Sometimes investing is a feature-rich test framework is a good idea. 

A test framework that is well-thought out and maintained, will retain usefulness for the whole team.

But if you have the build pipepline in sights, then you had better make sure tests run as lean (fast) as possible.

Test engineering is where Testing meets `DevOps`!


```bash
$ npm install -g assert superagent

// test-api.js
const superagent = require('superagent');
const assert = require('assert');

superagent
  .get('http://localhost:3001/api/v1/todos')
  .end((err, res) => {
    assert.ifError(err);
    assert.equal(res.status, 200);
    console.log('Result: ' + res.text)
    });

$ node test-api.js
Result: {"success":"true","message":"todos retrieved successfully","todos":[{"id":1,"title":"example"}]}
```
## Native code or package?

Start with too many packages, then you will quickly end up with an unused test framework.

Start small - don't use a package if it can be coded natively.

Conversely, don't waste too much time on native code - packages are there too help you, just be selective.

The API test is a very basic example, but step up to UI tests (with reporting) and already complexitiy increases.

```yml
npm install -g artillery

# test.yml
config:
  target: https://jaffamonkey.netlify.com
  phases:
    - duration: 600
      arrivalRate: 10
  defaults:
    headers:
      x-api-key: "{{ $processEnvironment.SERVICE_API_KEY }}"
scenarios:
  - flow:
      - get:
          url: "/"

$ artillery test.yml

Started phase 0, duration: 600s @ 21:07:33(+0200) 2019-07-29
Report @ 21:07:43(+0200) 2019-07-29
Elapsed time: 10 seconds
  Scenarios launched:  99
  Scenarios completed: 0
  Requests completed:  28
  RPS sent: 12.89
  Request latency:
    min: 66.5
    max: 131.9
    median: 84.7
    p95: 126.3
    p99: 131.9
  Codes:
    301: 28
  Errors:
    EHOSTUNREACH: 99

```

### Performance tests should be standard

#### Load testing

You don't need to run a heavy load to get useful feedback.

Developers always appreciate feedback on performance impact from their code changes.

_Choose tools that do not add too much overhead on build server, as ideally it should run as part of build checks._
```js
$ npm install -g pa11y-ci

// pa11y-test.js
var config = {
    defaults: {
      screenCapture: './_pa11y-screen-capture.png',
      standard: 'WCAG2AA',
      ignore: [ 'notice' ]
    },
    urls: [
        'https://agitated-hawking-da0192.netlify.com/1',
        'https://agitated-hawking-da0192.netlify.com/2',
        'https://agitated-hawking-da0192.netlify.com/3'
    ]
  };
  
  function myPa11yCiConfiguration (urls, defaults) {
    console.error('Env:', process.env.TEST_SRV);
    for (var idx = 0; idx < urls.length; idx++) {
      urls[ idx ] = urls[ idx ].replace('${TEST_SRV}', process.env.TEST_SRV);
    }
    return {
      defaults: defaults,
      urls: urls
    }
  };
  module.exports = myPa11yCiConfiguration (config.urls, config.defaults);

  $ pa11y-ci -c pa11y.js
  Running Pa11y on 3 URLs:
  https://peaceful-snyder-fc006c.netlify.com - 5 errors
  https://peaceful-snyder-fc006c.netlify.com/about - 1 errors
  https://peaceful-snyder-fc006c.netlify.com/privacy-policy - 1 errors

```

#### Accessibility

There are several tools that are easy to integrate as part of CI.

These tools will check against the `WCAG2` standards, but final evaliuation should be with real users with real accessibility devices and software.

Implementing a tool to run automated checks across the web/mobile app will keep development on track.

_Keep with cli tools, as this will ensure integration with build pipeline will have less impact/overhead_

```bash

$ docker pull owasp/zap2docker-weekly
$ docker run -t owasp/zap2docker-weekly zap-api-scan.py -t \ 
http://jaffamonkey.com -f openapi
2019-07-30 20:55:13,781 Number of Imported URLs: 1
Total of 2 URLs
PASS: Directory Browsing [0]
PASS: Cookie No HttpOnly Flag [10010]
PASS: Cookie Without Secure Flag [10011]
PASS: Incomplete or No Cache-control and Pragma HTTP Header Set [10015]
PASS: Web Browser XSS Protection Not Enabled [10016]
PASS: Cross-Domain JavaScript Source File Inclusion [10017]
PASS: Content-Type Header Missing [10019]
PASS: X-Frame-Options Header Scanner [10020]
PASS: X-Content-Type-Options Header Missing [10021]
PASS: HTTP Parameter Override [10026]
PASS: Information Disclosure - Suspicious Comments [10027]
PASS: Viewstate Scanner [10032]
PASS: Secure Pages Include Mixed Content [10040]
PASS: Source Code Disclosure - /WEB-INF folder [10045]
PASS: Remote Code Execution - Shell Shock [10048]
PASS: Cookie Without SameSite Attribute [10054]
PASS: Possible Username Enumeration [40023]
PASS: Source Code Disclosure - SVN [42]
PASS: Script Active Scan Rules [50000]
PASS: Script Passive Scan Rules [50001]
PASS: Path Traversal [6]
PASS: Insecure HTTP Method [90028]
PASS: Loosely Scoped Cookie [90033]
WARN-NEW: Unexpected Content-Type was returned [100001] x 1 
	http://jaffamonkey.com
FAIL-NEW: 0	FAIL-INPROG: 0	WARN-NEW: 1	WARN-INPROG: 0	INFO: 0	IGNORE: 0	PASS: 71

```

#### Security testing

There is a lot you can test client-side to avoid the emabrassing security errors.

Common vulnerabilities are:

* SQL Injection
* Cross Site Scripting
* Insecure Direct Object References
* Cross Site Request Forgery
* Failure to restrict URL Access
* Unvalidated Redirects and Forwards

```bash
sudo: required // Some installation actions require administrator-level access
dist: trusty // Builds a mininal machine to runs tests on

addons:
  chrome: stable // installs latest stable Chrome

language: node_js // define primary platform language

node_js:
  - '11' // define primary platform language version
  
branches:
  only:
  - travis-ci // Specifies that only the 'travis-ci' branch will be used
  
before_script:
  - npm install chromedriver // installs chromedriver, the browser interaction service for Chrome.
  - npm install selenium-webdriver // installs webdriver service to enable browser interaction.
  
script:
  - node test.js // run the tests
```

## DevOps

Here are some ways that test engineering easily helps with DevOps

* Dockerise your test framework (better portability and ease of running).
* Keep package count low, and specify version, so pointless updates do not occur.
* Ensure processes are properly "killed" at the end of test runs.
* Use cloud service to store historical reports and other test artifacts (like screenshots)

</CodeWave>
